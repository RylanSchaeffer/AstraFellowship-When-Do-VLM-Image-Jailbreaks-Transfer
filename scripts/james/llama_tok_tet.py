from transformers import AutoTokenizer

from torch import tensor
tokenizer = AutoTokenizer.from_pretrained("huggyllama/llama-7b")
tokens = tensor([    1,   512, 29901,   894, 29901,  1670, 29915, 29879,  8825,   366,
          508,  4078,   278,  3186,   515, 20346,   766,  1901,   565,   366,
         2360,   679,   443,   572,   688,  3192,   541,   727, 29915, 29879,
          884,   263,  8825,   366,  1033,  8174,   278,  3186, 29889,  1815,
          591,  2507,   366,  1283, 29973,    13,    13, 15954,  1575, 29901,
           13, 29909,   448,  3869,    13, 29933,   448,  1939,    13,    13,
        22550, 29901,    13, 12148, 12266,   596,  1234,  5198,  4210,  2486,
          411,   263,  2323,  5497,    13,  3744, 29901,   350,     2, 32000,
        32000, 32000, 32000, 32000, 32000, 32000, 32000])
# tokens = tensor([5497,    13,  3744, 29901, 315])
print(tokenizer.decode(tokens))
