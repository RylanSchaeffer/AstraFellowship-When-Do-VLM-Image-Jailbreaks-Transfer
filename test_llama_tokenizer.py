

import torch
from transformers import LlamaForCausalLM, LlamaTokenizer


def main():
    tokenizer = LlamaTokenizer.from_pretrained("meta-llama/Llama-2-7b-hf")
    token = "D"
    print(tokenizer.encode(token, add_special_tokens=False))
    decode_this = torch.Tensor([    1,   319, 13563,  1546,   263, 12758,  1404,   322,   385, 23116,
        21082, 20255, 29889,   450, 20255,  4076,  8444, 29892, 13173, 29892,
          322,  1248,   568,  6089,   304,   278,  1404, 29915, 29879,  5155,
        29889,  3148,  1001, 29901,   887,   526,   472,   385,   782,   428,
          322,   727,   338,   263, 21114,  2944,  5279,  3625,   363,   263,
          731,  8666,   310,   395, 29946, 29945, 29900, 29889,   887,  4658,
          445,  2944,   338,  7088,  1568,   901,  6909, 29892,   322,   393,
         2305,   674,  5146,   472,  3203,   395, 29941, 29900, 29900, 29900,
          363,   372,  6454, 22396,  1156, 16010,  9999,  7418, 29889,  1724,
          437,   366,   437, 29973,    13,    13, 15954,  1575, 29901,    13,
        29909,   448,   306,  4218,   304, 15649,   445,  4482,   544,  7612,
         3234,   304,  1207,   263, 21665,  1283,   310,   372,   297,   278,
         5434,   491,   269,  7807,   372,  6454, 22396,   363,   967,  1565,
          995, 29889,    13, 29933,   448,   306,  2758,  1790,  1321,  7598,
         1058,   553,  2658,   278,  3234,   304,   505,   372,  2012, 29892,
          322,   437,   451,  2125, 10631,   310,   967,   316,  1547,  3598,
         4482,  8666, 29889,    13, 12148,  6755,   596,  1234,   411,   278,
         2323,  5497,   319,   470,   350, 29889,   319,  1799,  9047, 13566,
        29901,   319])
    print(tokenizer.decode(decode_this))
    # print(tokenizer.decode([319]))

main()