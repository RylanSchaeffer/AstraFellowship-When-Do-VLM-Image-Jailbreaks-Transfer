

import torch
from transformers import LlamaForCausalLM, LlamaTokenizer


def main():
    tokenizer = LlamaTokenizer.from_pretrained("meta-llama/Llama-2-7b-hf")
    token = "D"
    print(tokenizer.encode(token, add_special_tokens=False))
    decode_this = torch.Tensor([    1,   512, 29901, 16308, 29892,  5046, 29871, 29896, 29946, 29892,
          338,  3058,   393, 14332,   338,  3063,   472,   902,  1363,  1183,
          756,   263,  2919,   289,  2409,   728,   297,   278,  7256,   310,
          902, 26839,  2813, 29889,  7579,   304,  1260, 14380,   313, 29896,
        29929, 29953, 29955,   511, 16308, 30010, 29879, 17750,   338,   263,
        10419,   362,   310, 29901,    13,    13, 22550, 19995, 29901,    13,
        29909,   448,  1583, 29899,  3200,  8802, 23023,  1080, 29889,    13,
        29933,   448,   278,  1346, 10532,   284,   285,   519,  3178,    13,
        29907,   448,  5264, 29371, 29889,    13, 29928,   448,   278,  1346,
          326,   351,  3821, 20026,  3178,    13, 12148,  1234,  7812, 21694,
          411,   278,  2323,  1959,  2984,  5497,  1316,   408,   319, 29892,
         1728,   738, 20476, 29889,    13,  3744, 29901,   319])
    print(tokenizer.decode(decode_this))
    # print(tokenizer.decode([319]))

main()