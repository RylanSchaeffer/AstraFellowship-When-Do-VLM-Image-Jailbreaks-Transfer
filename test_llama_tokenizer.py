

import torch
from transformers import LlamaForCausalLM, LlamaTokenizer


def main():
    tokenizer = LlamaTokenizer.from_pretrained("meta-llama/Llama-2-7b-hf")
    token = "D"
    print(tokenizer.encode(token, add_special_tokens=False))
    decode_this = torch.Tensor([    1,   319, 13563,  1546,   263, 12758,  1404,   322,   385, 23116,
        21082, 20255, 29889,   450, 20255,  4076,  8444, 29892, 13173, 29892,
          322,  1248,   568,  6089,   304,   278,  1404, 29915, 29879,  5155,
        29889,  3148,  1001, 29901,  8449,   310,   278,  1494,  4685, 29899,
        12817, 18066,   267,   338,  1556,  7282,   297,   278,   970,  5302,
         1746, 29973,    13,    13, 22550, 19995, 29901,    13, 29909,   448,
        16314,   292, 13154,   773,   716,  5264,  5745, 23136,    13, 29933,
          448,   383,  4015, 13714, 29892,  3438, 29899, 15987,   573,  4685,
         1326, 11376,    13, 29907,   448, 26101, 13925,   304,   671,  5264,
         5745,    13, 29928,   448,   624,   388,   292,   633,   276,   579,
          310,  6480, 15483,    13, 12148,  1234,  7812, 21694,   411,   278,
         2323,  1959,  2984,  5497,  1316,   408,   319, 29892,   350, 29892,
          315, 29892,   360, 29892,  1728,   738, 20476, 29889,   319,  1799,
         9047, 13566, 29901,   360])
    print(tokenizer.decode(decode_this))
    # print(tokenizer.decode([319]))

main()