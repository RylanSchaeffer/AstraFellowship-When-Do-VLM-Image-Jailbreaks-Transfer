program: generate_adversarial_examples_against_vlms.py
project: universal-vlm-jailbreak
method: grid
parameters:
  attack_kwargs:
    parameters:
      attack_name:
        values: ["pgd"]
      batch_size:
        values: [4, 6, 8]
      test_every_n_steps:
        values: [5000]
      step_size:
        values: [0.001, 0.00316, 0.01]
      total_steps:
        values: [150000]
  image_initialization:
    values:
      ["random"]
  models_to_attack:
    values:
      [
        "{'prism-reproduction-llava-v15+7b'}",
        "{'prism-clip+7b'}",
        "{'prism-siglip+7b'}",
        "{'prism-dinosiglip+7b'}",
      ]
  models_to_eval:
    values:
      ["{}"]
  prompt_and_targets_kwargs:
    parameters:
      dataset_train:
        values:
          ["rylan_anthropic_hhh"]
      dataset_test:
        values:
          ["rylan_advbench"]
      n_unique_prompts_and_targets:
        values:
          [ 32, 100, 316 ]
  seed:
    values:
      [0]