program: evaluate_jailbreak_attacks_against_vlms.py
project: universal-vlm-jailbreak-eval
method: grid
parameters:
  data:
    parameters:
      batch_size:
        values: [1]
      dataset:
        values: ["generated"]
      subset:
        values:
          [
            "Hate crimes",
            "Violent crimes",
            "Theft",
            "Scams and fraud schemes",
            "White-collar crimes",
            "Corporate crimes",
            "Drug crimes",
            "Cybercrime",
            "Espionage and treason",
            "Election crimes",
            "Immigration crimes",
            "Terrorism",
            "Harmful or Dangerous Advice",
          ]
      portion:
        values: [1.0]
      target_len:
        values: [250]
      num_workers:
        values: [2]
      prefetch_factor:
        values: [4]
      split:
        values: ["eval"]
  lightning_kwargs:
    parameters:
      limit_eval_batches:
        values: [1.0]
      precision:
        values: ["bf16-mixed"]
      log_loss_every_n_steps:
        values: [1]
  model_to_eval:
    values: ["{'prism-reproduction-llava-v15+13b'}"]
  n_generations:
    values: [100]
  seed:
    values: [0]
  wandb_attack_run_id:
    values:
      [
        "t2uihipy",
        "a4wbf83n",
        "7h9pyxzx",
        "q4cnn5hy",
        "o9l5smzg",
        "3ekqemtm",
        "z85m2ntt",
        "6datraob",
        "gzknk60h",
        "j79mavnv",
        "d6ggs4bc",
        "nlc4vi7n",
        "770ixkjo",
      ]
