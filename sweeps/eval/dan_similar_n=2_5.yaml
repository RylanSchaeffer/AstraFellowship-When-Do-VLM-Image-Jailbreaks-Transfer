program: evaluate_jailbreak_attacks_against_vlms.py
project: universal-vlm-jailbreak-eval
method: grid
parameters:
  data:
    parameters:
      batch_size:
        values: [1]
      dataset:
        values: ["generated"]
      portion:
        values: [1.0]
      target_len:
        values: [250]
      num_workers:
        values: [2]
      prefetch_factor:
        values: [4]
      split:
        values: ["eval"]
  lightning_kwargs:
    parameters:
      limit_eval_batches:
        values: [0.05]
      precision:
        values: ["bf16-mixed"]
      log_loss_every_n_steps:
        values: [1]
  model_to_eval:
    values:
      ["{'one-stage+7b'}", "{'train-1.25-epochs+7b'}", "{'train-3-epochs+7b'}"]
  n_generations:
    values: [100]
  seed:
    values: [0]
  wandb_attack_run_id:
    values: ["zjyp3tir"]
