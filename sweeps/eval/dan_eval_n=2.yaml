program: evaluate_jailbreak_attacks_against_vlms.py
project: universal-vlm-jailbreak-eval
method: grid
parameters:
  data:
    parameters:
      batch_size:
        values: [1]
      dataset:
        values: ["advbench", "rylan_anthropic_hhh", "generated"]
      portion:
        values: [0.02]
      target_len:
        values: [250]
      num_workers:
        values: [2]
      prefetch_factor:
        values: [4]
      split:
        values: ["eval"]
  lightning_kwargs:
    parameters:
      limit_eval_batches:
        values: [1.0]
      precision:
        values: ["bf16-mixed"]
      log_loss_every_n_steps:
        values: [1]
  model_to_eval:
    values:
      [
        "{'prism-reproduction-llava-v15+7b'}",
        "{'prism-reproduction-llava-v15+13b'}",
        "{'prism-clip+7b'}",
        "{'prism-clip+13b'}",
        "{'prism-siglip+7b'}",
        "{'prism-siglip+13b'}",
        "{'prism-dinosiglip+7b'}",
        "{'prism-dinosiglip+13b'}",
        "{'prism-clip-controlled+7b'}",
        "{'prism-clip-controlled+13b'}",
        "{'prism-siglip-controlled+7b'}",
        "{'prism-siglip-controlled+13b'}",
        "{'prism-dinosiglip-controlled+7b'}",
        "{'prism-dinosiglip-controlled+13b'}",
      ]
  n_generations:
    values: [100]
  seed:
    values: [0]
  wandb_attack_run_id:
    values:
      [
        "g2yhgpwe",
        "h50c46yd",
        "y427nyag",
        "cd4pbx4r",
        "7qe7umdr",
        "ymt6o3ou",
        "fm4elktj",
        "ucziqh6m",
        "58yoz7vs",
        "67hzkuqt",
      ]
