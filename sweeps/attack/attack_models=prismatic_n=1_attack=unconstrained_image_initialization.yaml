program: optimize_jailbreak_attacks_against_vlms.py
project: universal-vlm-jailbreak
method: grid
parameters:
  compile:
    values:
      [False]
  data:
    parameters:
      batch_size:
        values:
          [2]
      dataset:
        values:
          [
            "advbench",
          ]
      num_workers:
        values:
          [4]
      prefetch_factor:
        values: [ 4 ]
      split:
        values:
          ["train"]
  image_kwargs:
    parameters:
      image_size:
        values:
          [512]
      image_initialization:
        values:
          [
            "trina",
          ]
  lightning_kwargs:
    parameters:
      accumulate_grad_batches:
        values:
          [4]
      gradient_clip_val:
        values:
          [10.0]
      limit_train_batches:
        values:
          [1.0]
      log_loss_every_n_steps:
        values:
          [1]
      log_image_every_n_steps:
        values:
          [250]
      precision:
        values:
          ["bf16-mixed"]
  models_to_attack:
    values:
      [
        "{'prism-reproduction-llava-v15+7b'}",
        "{'prism-clip+7b'}",
        "{'prism-siglip+7b'}",
        "{'prism-dinosiglip+7b'}",
        "{'prism-clip-controlled+7b'}",
        "{'prism-siglip-controlled+7b'}",
        "{'prism-dinosiglip-controlled+7b'}",
        "{'deepseek-vl-7b-chat'}",
        "{'prism-gemma-instruct+2b+clip'}",
        "{'prism-gemma-instruct+2b+siglip'}",
        "{'prism-gemma-instruct+2b+dinosiglip'}",
        "{'prism-gemma-instruct+8b+clip'}",
        "{'prism-gemma-instruct+8b+siglip'}",
        "{'prism-gemma-instruct+8b+dinosiglip'}",
        "{'prism-llama2-chat+7b+clip'}",
        "{'prism-llama2-chat+7b+siglip'}",
        "{'prism-llama2-chat+7b+dinosiglip'}",
        "{'prism-llama3-instruct+8b+clip'}",
        "{'prism-llama3-instruct+8b+siglip'}",
        "{'prism-llama3-instruct+8b+dinosiglip'}",
        "{'prism-mistral-instruct-v0.2+7b+clip'}",
        "{'prism-mistral-instruct-v0.2+7b+siglip'}",
        "{'prism-mistral-instruct-v0.2+7b+dinosiglip'}",
        "{'Qwen-VL-Chat'}"
      ]
  n_generations:
    values:
      [30]
  n_grad_steps:
    values:
      [50000]
  optimization:
    parameters:
      eps:
        values:
          [0.0001]
      learning_rate:
        values:
          [0.001]
      momentum:
        values:
          [0.9]
      optimizer:
        values:
          ["adam"]
      weight_decay:
        values:
          [0.00001]
  seed:
    values:
      [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]